<!DOCTYPE html>
<html lang="zxx">

<head>
  <meta charset="utf-8">
  <title>THUHCSI</title>

  <!-- mobile responsive meta -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- ** Plugins Needed for the Project ** -->
  <!-- Bootstrap -->
  <link rel="stylesheet" href="plugins/bootstrap/bootstrap.min.css">
  <!-- slick slider -->
  <link rel="stylesheet" href="plugins/slick/slick.css">
  <!-- themefy-icon -->
  <link rel="stylesheet" href="plugins/themify-icons/themify-icons.css">
  <!-- animation css -->
  <link rel="stylesheet" href="plugins/animate/animate.css">
  <!-- aos -->
  <link rel="stylesheet" href="plugins/aos/aos.css">
  <!-- venobox popup -->
  <link rel="stylesheet" href="plugins/venobox/venobox.css">

  <!-- Main Stylesheet -->
  <link href="css/style.css" rel="stylesheet">

  <!--Favicon-->
  <link rel="shortcut icon" href="images/favicon.jpg" type="image/x-icon">
  <link rel="icon" href="images/favicon.jpg" type="image/x-icon">

</head>

<body>
  <!-- preloader start --
  <div class="preloader">
    <img src="images/hcsi-pre.gif" alt="preloader" width="500px">
  </div>
  <!-- preloader end -->

<!-- header -->
<header class="fixed-top header">
  <!-- navbar -->
  <div class="navigation w-100">
    <div class="container">
      <nav class="navbar navbar-expand-lg navbar-dark p-0">
        <!-- logo -->
        <a class="navbar-brand" href="index.html"><img src="images/logo.png" alt="logo" width="250"></a>
        <button class="navbar-toggler rounded-0" type="button" data-toggle="collapse" data-target="#navigation" aria-controls="navigation" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <!-- menu -->
        <div class="collapse navbar-collapse" id="navigation">
          <ul class="navbar-nav ml-auto text-center">
            <!-- about -->
            <li class="nav-item dropdown view @@about">
              <a class="nav-link dropdown-toggle" href="#" id="navbarAbout" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                About
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarAbout">
                <a class="dropdown-item" href="labintro.html">Introduction</a>
                <a class="dropdown-item" href="researches.html">Research Areas</a>
                <a class="dropdown-item" href="collaborators.html">Collaborators</a>
              </div>
            </li>
            <!-- members -->
            <li class="nav-item dropdown view @@members">
              <a class="nav-link dropdown-toggle" href="#" id="navbarMembers" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                Members
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarMembers">
                <a class="dropdown-item" href="zywu.html">Director</a>
                <a class="dropdown-item" href="members.html">Students</a>
                <a class="dropdown-item" href="alumni.html">Alumni</a>
                <a class="dropdown-item" href="honors.html">Honors</a>
              </div>
            </li>
            <!-- news -->
            <li class="nav-item @@news">
              <a class="nav-link" href="news.html">News</a>
            </li>
            <!-- research -->
            <li class="nav-item dropdown view active">
              <a class="nav-link dropdown-toggle" href="#" id="navbarResearch" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                Research
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarResearch">
                <a class="dropdown-item active" href="publications.html">Publications</a>
                <a class="dropdown-item" href="patents.html">Patents</a>
                <a class="dropdown-item" href="projects.html">Projects</a>
              </div>
            </li>
            <!-- awards -->
            <li class="nav-item @@awards">
              <a class="nav-link" href="awards.html">Awards</a>
            </li>
            <!-- demos -->
            <li class="nav-item @@demos">
              <a class="nav-link" href="demos.html">Demos</a>
            </li>
          </ul>
        </div>
        <!-- /menu -->
      </nav>
    </div>
  </div>
  <!-- /navbar -->
</header>
<!-- /header -->

<!-- page title -->
<section class="page-title-section overlay" data-background="images/backgrounds/hcsi-gather.jpg">
  <div class="container">
    <div class="row">
      <div class="col-md-8">
        <ul class="list-inline custom-breadcrumb">
          <li class="list-inline-item"><p class="h2 text-primary font-secondary">Publications</p></li>
          <li class="list-inline-item text-white h3 font-secondary"></li>
        </ul>
        <p class="text-lighten">&nbsp;</p>
      </div>
    </div>
  </div>
</section>
<!-- /page title -->

<!-- papers -->
<section class="section">
  <div class="container">
    <!-- paper category navigation bar -->
    <div class="row">
      <div class="col-12">
        <!-- nav tab -->
        <div class="border-bottom">
          <ul class="nav nav-pills text-center">
            <li class="navi-item">
              <a class="nav-link active" href="#year" data-toggle="pill">
                  by year
              </a>
            </li>
            <li class="navi-item">
              <a class="nav-link" href="#area" data-toggle="pill">
                  by area
              </a>
            </li>
            <li class="navi-item">
              <a class="nav-link" href="#cat" data-toggle="pill">
                  by category
              </a>
            </li>
          </ul>
        </div>
        <!-- nav tab content -->
        <div class="tab-content" id="pills-tabContent">
          <div class="tab-pane fade show active" id="year">
            <div class="col-12">
              <div class="mb-3"></div>
              <!-- paper category list -->
              <ul class="list-inline text-center filter-controls mb-3">
                <li class="list-inline-item px-2 mb-3 active" data-filter="all">All</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2022">2022</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2021">2021</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2020">2020</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2019">2019</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2018">2018</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2017">2017</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2016">2016</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2015">2015</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2014">2014</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2013">2013</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2012">2012</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2011">2011</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2010">2010</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2009">2009</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2008">2008</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2007">2007</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2006">2006</li>
                <li class="list-inline-item px-2 mb-3" data-filter="2005">2005</li>
              </ul>
            </div>
          </div>
          <div class="tab-pane fade" id="area">
            <div class="col-12">
              <div class="mb-3"></div>
              <!-- paper category list -->
              <ul class="list-inline text-center filter-controls mb-3">
                <li class="list-inline-item px-2 mb-3 active" data-filter="all">All</li>
                <li class="list-inline-item px-2 mb-3" data-filter="ss">Speech Synthesis</li>
                <li class="list-inline-item px-2 mb-3" data-filter="sr">Speech Recognition</li>
                <li class="list-inline-item px-2 mb-3" data-filter="sv">Speaker Recognition</li>
                <li class="list-inline-item px-2 mb-3" data-filter="ssp">Speech Signal Processing</li>
                <li class="list-inline-item px-2 mb-3" data-filter="ac">Affective Computing</li>
                <li class="list-inline-item px-2 mb-3" data-filter="mslp">Multimodal Speech and Language Processing</li>
              </ul>
            </div>
          </div>
          <div class="tab-pane fade" id="cat">
            <div class="col-12">
              <div class="mb-3"></div>
              <!-- paper category list -->
              <ul class="list-inline text-center filter-controls mb-3">
                <li class="list-inline-item px-2 mb-3 active" data-filter="all">All</li>
                <li class="list-inline-item px-2 mb-3" data-filter="jnl">Journal</li>
                <li class="list-inline-item px-2 mb-3" data-filter="cf">Conference</li>
                <li class="list-inline-item px-2 mb-3" data-filter="sel">Selected</li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- papers list -->
    <div class="filtr-container">
      <!-- paper -->
      <div data-category="2022,sel,jnl,sv" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Haibin Wu, Xu Li, Andy T Liu, Zhiyong Wu, Helen Meng, Hung-Yi Lee,
            "Improving the Adversarial Robustness for Speaker Verification by Self-supervised Learning,"
            <i>IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP)</i>,
            vol. 30, pp. 202-217. IEEE, January, 2022.
            <span class="text-lighten">(SCI: WOS:000742179300004, EI: 20215111368713, THU-A)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/document/9645217">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2022,cf,ss,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Shun Lei, Yixuan Zhou, Liyang Chen, Zhiyong Wu, Shiyin Kang, Helen Meng,
            "Towards Expressive Speaking Style Modelling with Hierarchical Context Information for Mandarin Speech Synthesis,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 7922-7926. Singapore, May 22-27, 2022.
            <span class="text-lighten">(EI: 20222312199470, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9747438">Paper</a>
            <a class="d-inline-block btn-round" href="https://thuhcsi.github.io/icassp2022-expressive-tts-hierarchical-context/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2022,cf,ss,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Jingbei Li, Yi Meng, Chenyi Li, Zhiyong Wu, Helen Meng, Chao Weng, Dan Su,
            "Enhancing Speaking Styles in Conversational Text-to-Speech Synthesis with Graph-Based Multi-Modal Context Modeling,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 7917-7921. Singapore, May 22-27, 2022.
            <span class="text-lighten">(EI, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9747837">Paper</a>
            <a class="d-inline-block btn-round" href="https://thuhcsi.github.io/icassp2022-conversational-tts/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2022,cf,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Liyang Chen, Zhiyong Wu, Jun Ling, Runnan Li, Xu Tan, Sheng Zhao,
            "Transformer-S2A: Robust and Efficient Speech-to-Animation,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 7247-7251. Singapore, May 22-27, 2022.
            <span class="text-lighten">(EI: 20222312198574, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9747495">Paper</a>
            <a class="d-inline-block btn-round" href="https://thuhcsi.github.io/icassp2022-Transformer-S2A/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2022,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xintao Zhao, Feng Liu, Changhe Song, Zhiyong Wu, Shiyin Kang, Deyi Tuo, Helen Meng,
            "Disentangling Content and Fine-Grained Prosody Information Via Hybrid ASR Bottleneck Features for Voice Conversion,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 7022-7026. Singapore, May 22-27, 2022.
            <span class="text-lighten">(EI: 20222312198907, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9747625">Paper</a>
            <a class="d-inline-block btn-round" href="https://thuhcsi.github.io/icassp2022-hybrid-bottleneck-vc/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2022,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xueyuan Chen, Changhe Song, Yixuan Zhou, Zhiyong Wu, Changbin Chen, Zhongqin Wu, Helen Meng,
            "A Character-Level Span-Based Model for Mandarin Prosodic Structure Prediction,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 7602-7606. Singapore, May 22-27, 2022.
            <span class="text-lighten">(EI: 20222312198495, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9747315">Paper</a>
            <a class="d-inline-block btn-round" href="https://github.com/thuhcsi/SpanPSP">Code</a>
            <a class="d-inline-block btn-round" href="https://thuhcsi.github.io/SpanPSP/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2022,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Wenlin Dai, Changhe Song, Xiang Li, Zhiyong Wu, Huashan Pan, Xiulin Li, Helen Meng,
            "An End-to-End Chinese Text Normalization Model Based on Rule-Guided Flat-Lattice Transformer,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 7122-7126. Singapore, May 22-27, 2022.
            <span class="text-lighten">(EI: 20222312198496, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9747316">Paper</a>
            <a class="d-inline-block btn-round" href="https://github.com/thuhcsi/FlatTN">Code</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2022,cf,ss,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Jingbei Li, Yi Meng, Zhiyong Wu, Helen Meng, Qiao Tian, Yuping Wang, Yuxuan Wang,
            "Neufa: Neural Network Based End-to-End Forced Alignment with Bidirectional Attention Mechanism,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 8007-8011. Singapore, May 22-27, 2022.
            <span class="text-lighten">(EI: 20222312198218, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9747085">Paper</a>
            <a class="d-inline-block btn-round" href="https://github.com/thuhcsi/NeuFA">Code</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2022,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Wenxuan Ye, Shaoguang Mao, Frank Soong, Wenshan Wu, Yan Xia, Jonathan Tien, Zhiyong Wu,
            "An Approach to Mispronunciation Detection and Diagnosis with Acoustic, Phonetic and Linguistic (APL) Embeddings,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 6827-6831. Singapore, May 22-27, 2022.
            <span class="text-lighten">(EI: 20222312199246, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9746604">Paper</a>
            <a class="d-inline-block btn-round" href="https://thuhcsi.github.io/icassp2022-MDD-APL/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2022,cf,ssp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Jun Chen, Zilin Wang, Deyi Tuo, Zhiyong Wu, Shiyin Kang, Helen Meng,
            "FullSubNet+: Channel Attention Fullsubnet with Complex Spectrograms for Speech Enhancement,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 7857-7861. Singapore, May 22-27, 2022.
            <span class="text-lighten">(EI, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9747888">Paper</a>
            <a class="d-inline-block btn-round" href="https://github.com/thuhcsi/FullSubNet-plus">Code</a>
            <a class="d-inline-block btn-round" href="https://hit-thusz-rookiecj.github.io/fullsubnet-plus.github.io/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2022,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xixin Wu, Shoukang Hu, Zhiyong Wu, Xunying Liu, Helen Meng,
            "Neural Architecture Search for Speech Emotion Recognition,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 6902-6906. Singapore, May 22-27, 2022.
            <span class="text-lighten">(EI: 20222312198129, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9746155">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2022,cf,sv" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Haibin Wu, Po-Chun Hsu, Ji Gao, Shanshan Zhang, Shen Huang, Jian Kang, Zhiyong Wu, Helen Meng, Hung-Yi Lee,
            "Adversarial Sample Detection for Speaker Verification by Neural Vocoders,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 236-240. Singapore, May 22-27, 2022.
            <span class="text-lighten">(EI: 20222312198990, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9746900">Paper</a>
            <a class="d-inline-block btn-round" href="https://github.com/hbwu-ntu/spot-adv-by-vocoder">Code</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,sel,jnl,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xixin Wu, Yuewen Cao, Hui Lu, Songxiang Liu, Disong Wang, Zhiyong Wu, Xunying Liu, Helen Meng,
            "Speech Emotion Recognition Using Sequential Capsule Networks,"
            <i>IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP)</i>,
            vol. 29, pp. 3280-3291. IEEE, October, 2021.
            <span class="text-lighten">(SCI: WOS:000714713700004, EI: 20214311082562, THU-A)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9576634">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,sel,jnl,ss,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xixin Wu, Yuewen Cao, Hui Lu, Songxiang Liu, Shiyin Kang, Zhiyong Wu, Xunying Liu, Helen Meng,
            "Exemplar-Based Emotive Speech Synthesis,"
            <i>IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP)</i>,
            vol. 29, pp. 874-886. IEEE, January, 2021.
            <span class="text-lighten">(SCI: WOS:000619310400001, EI: 20210409830187, THU-A)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9328288">Paper</a>
            <a class="d-inline-block btn-round" href="https://www1.se.cuhk.edu.hk/~wuxx/TASLP/ExemplarTTS.html">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,sel,cf,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yingmei Guo, Linjun Shou, Jian Pei, Ming Gong, Mingxing Xu, Zhiyong Wu, Daxin Jiang,
            "Learning from Multiple Noisy Augmented Data Sets for Better Cross-Lingual Spoken Language Understanding,"
            [in] <i>Proc. 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP)</i>,
            pp. 1-12. Punta Cana, Dominican Republic, November 7-11, 2021.
            <span class="text-lighten">(EI: 20221411909706, THU-A)</span>
            <a class="d-inline-block btn-round" href="https://arxiv.org/abs/2109.01583">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,sel,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yaohua Bu, Tianyi Ma, Weijun Li, Hang Zhou, Jia Jia, Shengqi Chen, Kaiyuan Xu, Dachuan Shi, Haozhe Wu, Zhihan Yang, Kun Li, Zhiyong Wu, Yuanchun Shi, Xiaobo Lu, Ziwei Liu,
            "PTeacher: A Computer-Aided Personalized Pronunciation Training System with Exaggerated Audio-Visual Corrective Feedback,"
            [in] <i>Proc. 2021 CHI Conference on Human Factors in Computing Systems (CHI)</i>,
            pp. 1-14. Yokohama, Japan, May 8-13, 2021.
            <span class="text-lighten">(EI: 20212210439123, CCF-A)</span>
            <a class="d-inline-block btn-round" href="https://dl.acm.org/doi/abs/10.1145/3411764.3445490">Paper</a>
            <a class="d-inline-block btn-round" href="https://hcsi.cs.tsinghua.edu.cn/demo/CHI21-BUYAOHUA.mp4">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,sel,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Suping Zhou, Jia Jia, Zhiyong Wu, Zhihan Yang, Yanfeng Wang, Wei Chen, Fanbo Meng, Shuo Huang, Jialie Shen, Xiaochuan Wang,
            "Inferring Emotion from Large-Scale Internet Voice Data: A Semi-supervised Curriculum Augmentation based Deep Learning Approach,"
            [in] <i>Proc. the 35th AAAI Conference on Artificial Intelligence (AAAI)</i>,
            pp. 6039-6047. Virtual, Online, February 2-9, 2021.
            <span class="text-lighten">(EI: 20222012114882, CCF-A)</span>
            <a class="d-inline-block btn-round" href="https://ojs.aaai.org/index.php/AAAI/article/view/16753">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,ss,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Liangqi Liu, Jiankun Hu, Zhiyong Wu, Song Yang, Songfan Yang, Jia Jia, Helen Meng,
            "Controllable Emphatic Speech Synthesis based on Forward Attention for Expressive Speech Synthesis,"
            [in] <i>Proc. IEEE Spoken Language Technology Workshop (SLT)</i>,
            pp. 410-414. Shenzhen, China, January 19-22, 2021.
            <span class="text-lighten">(EI: 20211510210781, <font color="#FF0000">Best Paper Finalist</font>)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9383537">Paper</a>
            <a class="d-inline-block btn-round" href="https://thuhcsi.github.io/slt2021-controllable-emphasis-tts/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Huirong Huang, Zhiyong Wu, Shiyin Kang, Dongyang Dai, Jia Jia, Tianxiao Fu, Deyi Tuo, Guangzhi Lei, Peng Liu, Dan Su, Dong Yu, Helen Meng,
            "Speaker Independent and Multilingual/Mixlingual Speech-driven Talking Head Generation Using Phonetic Posteriorgrams,"
            [in] <i>Proc. Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</i>,
            pp. 1433-1437. Tokyo, Japan, December 14-17, 2021.
            <span class="text-lighten">(EI: 20221211827369)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9689472">Paper</a>
            <a class="d-inline-block btn-round" href="https://thuhcsi.github.io/apsipa2021-talking-head-samples/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Aolan Sun, Jianzong Wang, Ning Cheng, Methawee Tantrawenith, Zhiyong Wu, Helen Meng, Edward Xiao, Jing Xiao,
            "Reconstructing Dual Learning for Neural Voice Conversion Using Relatively Few Samples,"
            [in] <i>Proc. IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</i>,
            pp. 946-953. December 13-17, 2021.
            <span class="text-lighten">(EI: 20221211830976)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9687965">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,ssp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xinyu Cai, Heinrich Dinkel, Zhiyong Yan, Yongqing Wang, Junbo Zhang, Zhiyong Wu, Yujun Wang,
            "A Contrastive Semi-Supervised Learning Framework For Anomaly Sound Detection,"
            [in] <i>Proc. Workshop on Detection and Classification of Acousitic Scenes and Events (DCASE)</i>,
            pp. 31-34. November 15â€“19, 2021.
            <a class="d-inline-block btn-round" href="https://dcase.community/documents/workshop2021/proceedings/DCASE2021Workshop_Cai_16.pdf">Paper</a>
            <a class="d-inline-block btn-round" href="https://github.com/bibiaaaa/SmallRice_DCASE2021Challenge">Code</a>
            <a class="d-inline-block btn-round" href="https://dcase.community/documents/workshop2021/posters/DCASE2021Workshop_Cai_16-poster.pdf">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Hui Lu, Zhiyong Wu, Xixin Wu, Xu Li, Shiyin Kang, Xunying Liu, Helen Meng,
            "VAENAR-TTS: Variational Auto-Encoder based Non-AutoRegressive Text-to-Speech Synthesis,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 3775-3779. Brno, Czech republic, August 30-September 3, 2021.
            <span class="text-lighten">(EI: 20214711186915, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://arxiv.org/abs/2107.03298">Paper</a>
            <a class="d-inline-block btn-round" href="https://github.com/thuhcsi/VAENAR-TTS">Code</a>
            <a class="d-inline-block btn-round" href="https://light1726.github.io/vaenar-tts/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,ss,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xiang Li, Changhe Song, Jingbei Li, Zhiyong Wu, Jia Jia, Helen Meng,
            "Towards Multi-Scale Style Control for Expressive Speech Synthesis,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 4673-4677. Brno, Czech republic, August 30-September 3, 2021.
            <span class="text-lighten">(EI: 20214711190435, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://arxiv.org/abs/2104.03521">Paper</a>
            <a class="d-inline-block btn-round" href="https://thuhcsi.github.io/interspeech2021-multi-scale-style-control/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Jie Wang, Jingbei Li, Xintao Zhao, Zhiyong Wu, Shiyin Kang, Helen Meng,
            "Adversarially Learning Disentangled Speech Representations for Robust Multi-factor Voice Conversion,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 846-850. Brno, Czech republic, August 30-September 3, 2021.
            <span class="text-lighten">(EI: 20214711194412, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://arxiv.org/abs/2102.00184">Paper</a>
            <a class="d-inline-block btn-round" href="https://thuhcsi.github.io/interspeech2021-multi-factor-vc/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,sv" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Haibin Wu, Yang Zhang, Zhiyong Wu, Dong Wang, Hung-Yi Lee,
            "Voting for the Right Answer: Adversarial Defense for Speaker Verification,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 4294-4298. Brno, Czech republic, August 30-September 3, 2021.
            <span class="text-lighten">(EI: 20214711194533, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://arxiv.org/abs/2106.07868">Paper</a>
            <a class="d-inline-block btn-round" href="https://github.com/thuhcsi/adsv_voting">Code</a>
            <a class="d-inline-block btn-round" href="https://zyzisyz.github.io/voting_audio_samples/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xingchen Song, Zhiyong Wu, Yiheng Huang, Chao Weng, Dan Su, Helen Meng,
            "Non-Autoregressive Transformer ASR with CTC-Enhanced Decoder Input,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 5894-5898. Toronto, Canada, June 6-11, 2021.
            <span class="text-lighten">(EI: 20213810913803, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9414694">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Changhe Song, Jingbei Li, Yixuan Zhou, Zhiyong Wu, Helen Meng,
            "Syntactic Representation Learning for Neural Network based TTS with Syntactic Parse Tree Traversal,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 6064-6068. Toronto, Canada, June 6-11, 2021.
            <span class="text-lighten">(EI: 20213810921439, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9414671">Paper</a>
            <a class="d-inline-block btn-round" href="https://thuhcsi.github.io/icassp2021-tree-tts/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,ss,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xiong Cai, Dongyang Dai, Zhiyong Wu, Xiang Li, Jingbei Li, Helen Meng,
            "Emotion Controllable Speech Synthesis using Emotion-Unlabeled Dataset with the Assistance of Cross-Domain Speech Emotion Recognition,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 5734-5738. Toronto, Canada, June 6-11, 2021.
            <span class="text-lighten">(EI: 20213810922222, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9413907">Paper</a>
            <a class="d-inline-block btn-round" href="https://github.com/thuhcsi/icassp2021-emotion-tts">Code</a>
            <a class="d-inline-block btn-round" href="https://thuhcsi.github.io/icassp2021-emotion-tts/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Jie Wnag, Yuren You, Feng Liu, Deyi Tuo, Shiyin Kang, Zhiyong Wu, Helen Meng,
            "The Huya Multi-speaker and Multi-style Speech Synthesis System for M2VOC Challenge 2020,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 8608-8612. Toronto, Canada, June 6-11, 2021.
            <span class="text-lighten">(EI: 20213810913901, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9414943">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,sv" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Haibin Wu, Xu Li, Andy T. Liu, Zhiyong Wu, Helen Meng, Hung-Yi Lee,
            "Adversarial Defense for Automatic Speaker Verification by Cascaded Self-supervised Learning Models,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 6718-6722. Toronto, Canada, June 6-11, 2021.
            <span class="text-lighten">(EI: 20213810914628, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9413737">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Bin Su, Shaoguang Mao, Frank Soong, Yan Xia, Jonathan Tien, Zhiyong Wu,
            "Improving Pronunciation Assessment via Ordinal Regression with Anchored Reference Samples,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 7748-7752. Toronto, Canada, June 6-11, 2021.
            <span class="text-lighten">(EI: 20213810908107, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9413659">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Qicong Xie, Xiaohai Tian, Guanghou Liu, Kun Song, Lei Xie, Zhiyong Wu, Hai Li, Song Shi, Haizhou Li, Fen Hong, Hui Bu, Xin Xu,
            "The Multi-speaker Multi-style Voice Cloning Challenge 2021,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 8613-8617. Toronto, Canada, June 6-11, 2021.
            <span class="text-lighten">(EI: 20213810922367, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9414001">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xiong Cai, Zhiyong Wu, Kuo Zhong, Bin Su, Dongyang Dai, Helen Meng,
            "Unsupervised Cross-Lingual Speech Emotion Recognition Using Domain Adversarial Neural Network,"
            [in] <i>Proc. International Symposium on Chinese Spoken Language Processing (ISCSLP)</i>,
            pp. 1-5. Hong Kong, China, January 24-26, 2021.
            <span class="text-lighten">(EI: 20211210098767)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9362058">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2021,cf,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Michael Lao BanTeng, Zhiyong Wu,
            "Channel-Wise Dense Connection Graph Convolutional Network for Skeleton-Based Action Recognition,"
            [in] <i>Proc. International Conference on Pattern Recognition (ICPR)</i>,
            pp. 3799-3806. Milan, Italy, January 10-15, 2021.
            <span class="text-lighten">(EI: 20212910658234, THU-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9412329">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2020,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xingchen Song, Zhiyong Wu, Yiheng Huang, Dan Su, Helen Meng,
            "SpecSwap: A Simple Data Augmentation Method for End-to-End Speech Recognition,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 581-585. Shanghai, China, October 25-29, 2020.
            <span class="text-lighten">(EI: 20205209692178, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2020/abstracts/2275.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2020,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xingchen Song, Guangsen Wang, Yiheng Huang, Zhiyong Wu, Dan Su, Helen Meng,
            "Speech-XLNet: Unsupervised Acoustic Model Pretraining For Self-Attention Networks,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 3765-3769. Shanghai, China, October 25-29, 2020.
            <span class="text-lighten">(EI: 20205209692164, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2020/abstracts/1511.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2020,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Kun Zhang, Zhiyong Wu, Daode Yuan, Jian Luan, Jia Jia, Helen Meng, Binheng Song,
            "Re-weighted Interval Loss for Handling Data Imbalance Problem of End-to-End Keyword Spotting,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 2567-2571. Shanghai, China, October 25-29, 2020.
            <span class="text-lighten">(EI: 20205209692622, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2020/abstracts/1644.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2020,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xiangyu Liang, Zhiyong Wu, Runnan Li, Yanqing Liu, Sheng Zhao, Helen Meng,
            "Enhancing Monotonicity for Robust Autoregressive Transformer TTS,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 3181-3185. Shanghai, China, October 25-29, 2020.
            <span class="text-lighten">(EI: 20205209692668, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2020/abstracts/1751.html">Paper</a>
            <a class="d-inline-block btn-round" href="https://thuhcsi.github.io/interspeech2020-monotonicity-transformer-tts/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2020,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yuewen Cao, Songxiang Liu, Xixin Wu, Shiyin Kang, Peng Liu, Zhiyong Wu, Xunying Liu, Dan Su, Dong Yu, Helen Meng,
            "Code-Switched Speech Synthesis Using Bilingual Phonetic Posteriorgram with Only Monolingual Corpora,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 7619-7623. Barcelona, Spain, May 4-8, 2020.
            <span class="text-lighten">(EI: 20203309041046, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9053094">Paper</a>
            <a class="d-inline-block btn-round" href="https://csttsdemo.github.io/bppgCSTTS/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2020,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Songxiang Liu, Disong Wang, Yuewen Cao, Lifa Sun, Xixin Wu, Shiyin Kang, Zhiyong Wu, Xunying Liu, Dan Su, Dong Yu, Helen Meng,
            "End-To-End Accent Conversion Without Using Native Utterances,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 6289-6293. Barcelona, Spain, May 4-8, 2020.
            <span class="text-lighten">(EI: 20203309040748, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9053797">Paper</a>
            <a class="d-inline-block btn-round" href="https://liusongxiang.github.io/end2endAC/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2020,cf,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yingmei Guo, Zhiyong Wu, Mingxing Xu,
            "FERNet: Fine-grained Extraction and Reasoning Network for Emotion Recognition in Dialogues,"
            [in] <i>Proc. Asia-Pacific Chapter of the Association for Computational Linguistics and International Joint Conference on Natural Language Processing (AACL-IJCNLP)</i>,
            pp. 37-43. Suzhou, China, December 4-7, 2020.
            <a class="d-inline-block btn-round" href="https://aclanthology.org/2020.aacl-main.5/">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,sel,cf,ac,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Runnan Li, Zhiyong Wu, Jia Jia, Yaohua Bu, Sheng Zhao, Helen Meng,
            "Towards Discriminative Representation Learning for Speech Emotion Recognition,"
            [in] <i>Proc. International Joint Conference on Artificial Intelligence (IJCAI)</i>,
            pp. 5060-5066. Macao, China, August 10-16, 2019.
            <span class="text-lighten">(EI: 20194607696464, CCF-A)</span>
            <a class="d-inline-block btn-round" href="https://www.ijcai.org/proceedings/2019/0703.pdf">Paper</a>
            <a class="d-inline-block btn-round" href="https://github.com/thuhcsi/IJCAI2019-DRL4SER">Code</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,sel,jnl,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yishuang Ning, Sheng He, Zhiyong Wu, Chunxiao Xing, Liangjie Zhang,
            "A Review of Deep Learning Based Speech Synthesis,"
            <i>Applied Sciences-Basel</i>,
            vol. 9, no. 19, pp. 4050. MDPI, September, 2019.
            <span class="text-lighten">(SCI: WOS:000496258100108)</span>
            <a class="d-inline-block btn-round" href="https://www.mdpi.com/2076-3417/9/19/4050">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Liangqi Liu, Zhiyong Wu, Runnan Li, Jia Jia, Helen Meng,
            "Learning Contextual Representation with Convolution Bank and Multi-head Self-attention for Speech Emphasis Detection,"
            [in] <i>Proc. APSIPA Annual Summit and Conference (APSIPA ASC)</i>,
            pp. 922-926. Lanzhou, China, November 18-21, 2019.
            <span class="text-lighten">(EI: 20201308362271)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9023243">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Kun Zhang, Zhiyong Wu, Jia Jia, Helen Meng, Binheng Song,
            "Query-by-Example Spoken Term Detection using Attentive Pooling Networks,"
            [in] <i>Proc. APSIPA Annual Summit and Conference (APSIPA ASC)</i>,
            pp. 1267-1272. Lanzhou, China, November 18-21, 2019.
            <span class="text-lighten">(EI: 20201308362101)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9023023">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yao Du, Zhiyong Wu, Shiyin Kang, Dan Su, Dong Yu, Helen Meng,
            "Automatic Prosodic Structure Labeling using DNN-BGRU-CRF Hybrid Neural Network,"
            [in] <i>Proc. APSIPA Annual Summit and Conference (APSIPA ASC)</i>,
            pp. 1234-1238. Lanzhou, China, November 18-21, 2019.
            <span class="text-lighten">(EI: 20201308362428)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9023299">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yao Du, Zhiyong Wu, Shiyin Kang, Dan Su, Dong Yu, Helen Meng,
            "Prosodic Structure Prediction using Deep Self-attention Neural Network,"
            [in] <i>Proc. APSIPA Annual Summit and Conference (APSIPA ASC)</i>,
            pp. 320-324. Lanzhou, China, November 18-21, 2019.
            <span class="text-lighten">(EI: 20201308362388)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/9023259">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yulan Chen, Zhiyong Wu, Jia Jia,
            "Modeling Emotion Influence Using Attention-based Graph Convolutional Recurrent Network,"
            [in] <i>Proc. International Conference on Multimodal Interaction (ICMI)</i>,
            pp. 302-309. Suzhou, China, October 14-18, 2019.
            <span class="text-lighten">(EI: 20194607696646, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://dl.acm.org/doi/abs/10.1145/3340555.3353719">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Hui Lu, Zhiyong Wu, Dongyang Dai, Runnan Li, Shiyin Kang, Jia Jia, Helen Meng,
            "One-shot Voice Conversion with Global Speaker Embeddings,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 669-673. Graz, Austria, September 15-19, 2019.
            <span class="text-lighten">(EI: 20194607674295, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2019/abstracts/2365.html">Paper</a>
            <a class="d-inline-block btn-round" href="https://daidongyang.github.io/vc-eval/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Dongyang Dai, Zhiyong Wu, Shiyin Kang, Xixin Wu, Jia Jia, Dan Su, Dong Yu, Helen Meng,
            "Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-trained BERT,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 2090-2094. Graz, Austria, September 15-19, 2019.
            <span class="text-lighten">(EI: 20194607674520, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2019/abstracts/2292.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Jingbei Li, Zhiyong Wu, Runnan Li, Pengpeng Zhi, Song Yang, Helen Meng,
            "Knowledge-based Linguistic Encoding for End-to-End Mandarin Text-to-Speech Synthesis,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 4494-4498. Graz, Austria, September 15-19, 2019.
            <span class="text-lighten">(EI: 20194607674398, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2019/abstracts/1118.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,ssp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yingmei Guo, Mingxing Xu, Zhiyong Wu, Jianming Wu, Bin Su,
            "Multi-Scale Convolutional Recurrent Neural Network with Ensemble Method for Weakly Labeled Sound Event Detection,"
            [in] <i>Proc. International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)</i>,
            pp. 110-114. Cambridge, UK, September 3-6, 2019.
            <span class="text-lighten">(EI: 20200308046817)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8925176">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Dongyang Dai, Zhiyong Wu, Runnan Li, Xixin Wu, Jia Jia, Helen Meng,
            "Learning Discriminative Features from Spectrograms Using Center Loss for Speech Emotion Recognition,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 7405-7409. Brighton, UK, May 12-17, 2019.
            <span class="text-lighten">(EI: 20193007228731, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8683765">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Hui Lu, Zhiyong Wu, Runnan Li, Shiyin Kang, Jia Jia, Helen Meng,
            "A Compact Framework for Voice Conversion Using Wavenet Conditioned on Phonetic Posteriorgrams,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 6810-6814. Brighton, UK, May 12-17, 2019.
            <span class="text-lighten">(EI: 20192907201683, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8682938">Paper</a>
            <a class="d-inline-block btn-round" href="https://light1726.github.io/voice_conversion_demo/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Mu Wang, Xixin Wu, Zhiyong Wu, Shiyin Kang, Deyi Tuo, Guangzhi Li, Dan Su, Dong Yu, Helen Meng,
            "Quasi-fully Convolutional Neural Network with Variational Inference for Speech Synthesis,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 7060-7064. Brighton, UK, May 12-17, 2019.
            <span class="text-lighten">(EI: 20192907202523, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8682528">Paper</a>
            <a class="d-inline-block btn-round" href="https://mu94w.github.io/QFCVI/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Runnan Li, Zhiyong Wu, Jia Jia, Sheng Zhao, Helen Meng,
            "Dilated Residual Network with Multi-head Self-attention for Speech Emotion Recognition,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 6675-6679. Brighton, UK, May 12-17, 2019.
            <span class="text-lighten">(EI: 20192907202018, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8682154">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Shaoguang Mao, Zhiyong Wu, Jingshuai Jiang, Peiyun Liu, Frank K. Soong,
            "NN-based Ordinal Regression for Assessing Fluency of ESL Speech,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 7420-7424. Brighton, UK, May 12-17, 2019.
            <span class="text-lighten">(EI: 20192907202051, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8682187">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xixin Wu, Songxiang Liu, Yuewen Cao, Xu Li, Jianwei Yu, Dongyang Dai, Xi Ma, Shoukang Hu, Zhiyong Wu, Xunying Liu, Helen Meng,
            "Speech Emotion Recognition Using Capsule Networks,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 6695-6699. Brighton, UK, May 12-17, 2019.
            <span class="text-lighten">(EI: 20192907201454, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8683163">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2019,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yuewen Cao, Xixin Wu, Songxiang Liu, Jianwei Yu, Xu Li, Zhiyong Wu, Xunying Liu, Helen Meng,
            "End-to-End Code-switched TTS with Mix of Monolingual Recordings,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 6935-6939. Brighton, UK, May 12-17, 2019.
            <span class="text-lighten">(EI: 20192907201672, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8682927">Paper</a>
            <a class="d-inline-block btn-round" href="https://csttsdemo.github.io/">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,sel,cf,ac,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Runnan Li, Zhiyong Wu, Jia Jia, Jingbei Li, Wei Chen, Helen Meng,
            "Inferring User Emotive State Changes in Realistic Human-Computer Conversational Dialogs,"
            [in] <i>Proc. ACM Multimedia Conference (ACM MM)</i>,
            pp. 136-144. Seoul, Korea, October 22-26, 2018.
            <span class="text-lighten">(EI: 20185006246269, CCF-A)</span>
            <a class="d-inline-block btn-round" href="https://dl.acm.org/doi/abs/10.1145/3240508.3240575">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,sel,jnl,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Kun Li, Shaoguang Mao, Xu Li, Zhiyong Wu, Helen Meng,
            "Automatic Lexical Stress and Pitch Accent Detection for L2 English Speech using Multi-Distribution Deep Neural Networks,"
            <i>Speech Communication (Speech Com)</i>,
            vol. 96, pp. 28-36. Elsevier, February, 2018.
            <span class="text-lighten">(SCI: WOS:000424723700003, EI: 20174704448303, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://www.sciencedirect.com/science/article/pii/S0167639315300637">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Jingbei Li, Zhiyong Wu, Runnan Li, Mingxing Xu, Kehua Lei, Lianhong Cai,
            "Multi-modal Multi-scale Speech Expression Evaluation in Computer-Assisted Language Learning,"
            <i>Lecture Notes in Computer Science</i>,
            [in] <i>Proc. Artificial Intelligence and Mobile Services (AIMS)</i>,
            vol. 10970, pp. 16-28. Seattle, USA, June 25-30, 2018.
            <span class="text-lighten">(SCI: WOS:000443112000002, EI: 20182705519834)</span>
            <a class="d-inline-block btn-round" href="https://link.springer.com/chapter/10.1007/978-3-319-94361-9_2">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Ziwei Zhu, Zhiyong Wu, Runnan Li, Yishuang Ning, Helen Meng,
            "Learning Frame-Level Recurrent Neural Networks Representations for Query-by-Example Spoken Term Detection on Mobile Devices,"
            <i>Lecture Notes in Computer Science</i>,
            [in] <i>Proc. Artificial Intelligence and Mobile Services (AIMS)</i>,
            vol. 10970, pp. 55-66. Seattle, USA, June 25-30, 2018.
            <span class="text-lighten">(SCI: WOS:000443112000005, EI: 20182705519838)</span>
            <a class="d-inline-block btn-round" href="https://link.springer.com/chapter/10.1007/978-3-319-94361-9_5">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Mu Wang, Zhiyong Wu, Shiyin Kang, Xixin Wu, Jia Jia, Dan Su, Dong Yu, Helen Meng,
            "Speech Super Resolution Using Parallel WaveNet,"
            [in] <i>Proc. International Symposium on Chinese Spoken Language Processing (ISCSLP)</i>,
            pp. 260-264. Taipei, China, November 26-29, 2018.
            <span class="text-lighten">(EI: 20192106959272)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8706637">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Ziwei Zhu, Zhiyong Wu, Runnan Li, Helen Meng, Lianhong Cai,
            "Siamese Recurrent Auto-Encoder Representation for Query-by-Example Spoken Term Detection,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 102-106. Hyderabad, India, September 2-6, 2018.
            <span class="text-lighten">(EI: 20184305969082, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2018/abstracts/1788.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,cf,ss,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xixin Wu, Yuewen Cao, Mu Wang, Songxiang Liu, Shiyin Kang, Zhiyong Wu, Xunying Liu, Dan Su, Dong Yu, Helen Meng,
            "Rapid Style Adaptation using Residual Error Embedding for Expressive Speech Synthesis,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 3072-3076. Hyderabad, India, September 2-6, 2018.
            <span class="text-lighten">(EI: 20184305968770, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2018/abstracts/1991.html">Paper</a>
            <a class="d-inline-block btn-round" href="https://www1.se.cuhk.edu.hk/~wuxx/IS18/eenstyle.html">Demo</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,cf,sr,ssp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Shuai Yang, Zhiyong Wu, Binbin Shen, Helen Meng,
            "Detection of Glottal Closure Instants from Speech Signals: A Convolutional Neural Network based Method,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 317-321. Hyderabad, India, September 2-6, 2018.
            <span class="text-lighten">(EI: 20184305968631, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2018/abstracts/1281.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xi Ma, Zhiyong Wu, Jia Jia, Mingxing Xu, Helen Meng, Lianhong Cai,
            "Emotion Recognition from Variable-Length Speech Segments using Deep Learning on Spectrograms,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 3683-3687. Hyderabad, India, September 2-6, 2018.
            <span class="text-lighten">(EI: 20184305969207, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2018/abstracts/2228.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Shaoguang Mao, Zhiyong Wu, Xu Li, Runnan Li, Xixin Wu, Helen Meng,
            "Integrating Articulatory Features into Acoustic-Phonemic Model for Mispronunciation Detection and Diagnosis in L2 English Speech,"
            [in] <i>Proc. IEEE International Conference on Multimedia and Expo (ICME)</i>,
            pp. 1-6. San Diego, USA, July 23-27, 2018.
            <span class="text-lighten">(EI: 20190706509298, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8486462">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,cf,ss,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Runnan Li, Zhiyong Wu, Yuchen Huang, Jia Jia, Helen Meng, Lianhong Cai,
            "Emphatic Speech Generation with Conditional Input Layer and Bidirectional LSTMs for Expressive Speech Synthesis,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 5129-5133. Calgary, Canada, April 15-20, 2018.
            <span class="text-lighten">(EI: 20184005908536, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8461748">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Shaoguang Mao, Zhiyong Wu, Runnan Li, Xu Li, Helen Meng, Lianhong Cai,
            "Applying Multitask Learning to Acoustic-Phonemic Model for Mispronunciation Detection and Diagnosis in L2 English Speech,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 6254-6258. Calgary, Canada, April 15-20, 2018.
            <span class="text-lighten">(EI: 20184005907878, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8461841">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Shaoguang Mao, Xu Li, Kun Li, Zhiyong Wu, Xunying Liu, Helen Meng,
            "Unsupervised Discovery of An Extended Phoneme Set in L2 English Speech for Mispronunciation Detection and Diagnosis,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 6244-6248. Calgary, Canada, April 15-20, 2018.
            <span class="text-lighten">(EI: 20184005908409, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8462635">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,cf,ss,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xixin Wu, Lifa Sun, Shiyin Kang, Songxiang Liu, Zhiyong Wu, Xunying Liu, Helen Meng,
            "Feature based Adaptation for Speaking Style Synthesis,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 5304-5308. Calgary, Canada, April 15-20, 2018.
            <span class="text-lighten">(EI: 20184005907958, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8462178">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2018,cf,ss,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Mu Wang, Zhiyong Wu, Xixin Wu, Helen Meng, Shiyin Kang, Jia Jia, Lianhong Cai,
            "Emphatic Speech Synthesis and Control based on Characteristic Transferring in End-to-End Speech Synthesis,"
            [in] <i>Proc. Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia)</i>,
            pp. 1-6. Beijing, China, May 20-22, 2018.
            <span class="text-lighten">(EI: 20184406009875)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/8470334">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2017,sel,cf,ac,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yishuang Ning, Jia Jia, Zhiyong Wu, Runnan Li, Yongsheng An, Yanfeng Wang, Helen Meng,
            "Multi-task Deep Learning for User Intention Understanding in Speech Interaction Systems,"
            [in] <i>Proc. AAAI Conference on Artificial Intelligence (AAAI)</i>,
            pp. 161-167. San Francisco, USA, February 4-9, 2017.
            <span class="text-lighten">(EI: 20174104242835, CCF-A)</span>
            <a class="d-inline-block btn-round" href="https://ojs.aaai.org/index.php/AAAI/article/view/10493">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2017,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Runnan Li, Zhiyong Wu, Yishuang Ning, Lifa Sun, Helen Meng, Lianhong Cai,
            "Spectro-Temporal Modelling with Time-Frequency LSTM and Structured Output Layer for Voice Conversion,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 3409-3413. Stockholm, Sweden, August 20-24, 2017.
            <span class="text-lighten">(EI: 20175204590811, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2017/abstracts/1122.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2017,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yuchen Huang, Zhiyong Wu, Runnan Li, Helen Meng, Lianhong Cai,
            "Multi-Task Learning for Prosodic Structure Generation using BLSTM RNN with Structured Output Layer,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 779-783. Stockholm, Sweden, August 20-24, 2017.
            <span class="text-lighten">(EI: 20175204591488, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2017/abstracts/0949.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2017,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xi Ma, Zhiyong Wu, Jia Jia, Mingxing Xu, Helen Meng, Lianhong Cai,
            "Speech Emotion Recognition with Emotion-Pair based Framework Considering Emotion Distribution Information in Dimensional Emotion Space,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 1238-1242. Stockholm, Sweden, August 20-24, 2017.
            <span class="text-lighten">(EI: 20175204591394, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2017/abstracts/0619.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2017,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yishuang Ning, Zhiyong Wu, Runnan Li, Jia Jia, Mingxing Xu, Helen Meng, Lianhong Cai,
            "Learning Cross-Lingual Knowledge with Multilingual BLSTM for Emphasis Detection with Limited Training Data,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 5615-5619. New Orleans, USA, March 5-9, 2017.
            <span class="text-lighten">(EI: 20172903955037, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/7953231">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2017,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Runnan Li, Zhiyong Wu, Xunying Liu, Helen Meng, Lianhong Cai,
            "Multi-Task Learning of Structured Output Layer Bidirectional LSTMs for Speech Synthesis,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 5510-5514. New Orleans, USA, March 5-9, 2017.
            <span class="text-lighten">(EI: 20172903955266, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/7953210">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2017,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xixin Wu, Shiyin Kang, Lifa Sun, Yishuang Ning, Zhiyong Wu, Helen Meng,
            "Attention-based Recurrent Generator with Gaussian Tolerance for Statistical Parametric Speech Synthesis,"
            [in] <i>Proc. Affective Social Multimedia Computing (ASMMC)</i>,
            pp. 1-5. Stockholm, Sweden, August 20-24, 2017.
            <a class="d-inline-block btn-round" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/2017_asmmc_camera_xixin.pdf">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2016,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Runnan Li, Zhiyong Wu, Helen Meng, Lianhong Cai,
            "DBLSTM-based Multi-Task Learning for Pitch Transformation in Voice Conversion,"
            [in] <i>Proc. International Symposium on Chinese Spoken Language Processing (ISCSLP)</i>,
            pp. 1-5. Tianjin, China, October 17-20, 2016.
            <span class="text-lighten">(EI: 20172303743441)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/7918466">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2016,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xu Li, Zhiyong Wu, Helen Meng, Jia Jia, Xiaoyan Lou, Lianhong Cai,
            "Phoneme Embedding and its Application to Speech Driven Talking Avatar Synthesis,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 1472-1476. San Francisco, USA, September 8-12, 2016.
            <span class="text-lighten">(EI: 20164603004231, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2016/abstracts/0363.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2016,cf,ss,ac,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xu Li, Zhiyong Wu, Helen Meng, Jia Jia, Xiaoyan Lou, Lianhong Cai,
            "Expressive Speech Driven Talking Avatar Synthesis with DBLSTM using Limited Amount of Emotional Bimodal Data,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 1477-1481. San Francisco, USA, September 8-12, 2016.
            <span class="text-lighten">(EI: 20164603004232, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2016/abstracts/0364.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2016,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yaodong Tang, Zhiyong Wu, Helen Meng, Mingxing Xu, Lianhong Cai,
            "Analysis on Gated Recurrent Unit based Question Detection Approach,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 735-739. San Francisco, USA, September 8-12, 2016.
            <span class="text-lighten">(EI: 20164603003979, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2016/abstracts/0964.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2016,cf,ac,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Linchuan Li, Zhiyong Wu, Mingxing Xu, Helen Meng, Lianhong Cai,
            "Combining CNN and BLSTM to Extract Textual and Acoustic Features for Recognizing Stances in Mandarin Ideological Debate Competition,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 1392-1396. San Francisco, USA, September 8-12, 2016.
            <span class="text-lighten">(EI: 20164603003717, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/Interspeech_2016/abstracts/0324.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2016,cf,ac,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Linchuan Li, Zhiyong Wu, Mingxing Xu, Helen Meng, Lianhong Cai,
            "Recognizing Stances in Mandarin Social Ideological Debates with Text and Acoustic Features,"
            [in] <i>Proc. IEEE International Conference on Multimedia and Expo (ICME)</i>,
            pp. 1-6. Seattle, USA, July 11-15, 2016.
            <span class="text-lighten">(EI: 20164302952120, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/7574751">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2016,cf,ac,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Haishu Xianyu, Mingxing Xu, Zhiyong Wu, Lianhong Cai,
            "Heterogeneity-Entropy based Unsupervised Feature Learning for Personality Prediction with Cross-media Data,"
            [in] <i>Proc. IEEE International Conference on Multimedia and Expo (ICME)</i>,
            pp. 1-6. Seattle, USA, July 11-15, 2016.
            <span class="text-lighten">(EI: 20163802815545, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/7552980">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2016,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yaodong Tang, Yuchen Huang, Zhiyong Wu, Helen Meng, Mingxing Xu, Lianhong Cai,
            "Question Detection from Acoustic Features using Recurrent Neural Network with Gated Recurrent Unit,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 6125-6129. Shanghai, China, March 20-25, 2016.
            <span class="text-lighten">(EI: 20162402488463, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/7472854">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2016,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Quanjie Yu, Peng Liu, Zhiyong Wu, Shiyin Kang, Helen Meng, Lianhong Cai,
            "Learning Cross-lingual Information with Multilingual BLSTM for Speech Synthesis of Low-resource Languages,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 5545-5549. Shanghai, China, March 20-25, 2016.
            <span class="text-lighten">(EI: 20162402488723, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/7472738">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2016,cf,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xinyu Lan, Xu Li, Yishuang Ning, Zhiyong Wu, Helen Meng, Jia Jia, Lianhong Cai,
            "Low Level Descriptors based DBLSTM Bottleneck Feature for Speech Driven Talking Avatar,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 5550-5554. Shanghai, China, March 20-25, 2016.
            <span class="text-lighten">(EI: 20162402488482, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/7472739">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2015,sel,jnl,ss,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Zhiyong Wu, Yishuang Ning, Xiao Zang, Jia Jia, Fanbo Meng, Helen Meng, Lianhong Cai,
            "Generating Emphatic Speech with Hidden Markov Model for Expressive Speech Synthesis,"
            <i>Multimedia Tools and Applications (MTA)</i>,
            vol. 74, no. 22, pp. 9909-9925. Springer, July, 2015.
             <span class="text-lighten">(SCI: WOS:000364019400005, EI: 20143600027913, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://link.springer.com/article/10.1007/s11042-014-2164-2">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2015,sel,jnl,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Zhiyong Wu, Kai Zhao, Xixin Wu, Xinyu Lan, Helen Meng,
            "Acoustic to Articulatory Mapping with Deep Neural Network,"
            <i>Multimedia Tools and Applications (MTA)</i>,
            vol. 74, no. 22, pp. 9889-9907. Springer, August, 2015.
            <span class="text-lighten">(SCI: WOS:000364019400004, EI: 20143600014973, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://link.springer.com/article/10.1007/s11042-014-2183-z">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2015,sel,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Qi Lyu, Zhiyong Wu, Jun Zhu,
            "Polyphonic Music Modelling with LSTM-RTRBM,"
            [in] <i>Proc. ACM Multimedia Conference (ACM MM)</i>,
            pp. 991-994. Brisbane, Australia, October 26-30, 2015.
            <span class="text-lighten">(EI: 20161602252616, CCF-A)</span>
            <a class="d-inline-block btn-round" href="https://dl.acm.org/doi/abs/10.1145/2733373.2806383">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2015,sel,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Qi Lyu, Zhiyong Wu, Jun Zhu, Helen Meng,
            "Modelling High-dimensional Sequences with LSTM-RTRBM: Application to Polyphonic Music Generation,"
            [in] <i>Proc. International Joint Conference on Artificial Intelligence (IJCAI)</i>,
            pp. 4138-4139. Buenos Aires, Argentina, July 25-31, 2015.
            <span class="text-lighten">(EI: 20155101693661, CCF-A)</span>
            <a class="d-inline-block btn-round" href="https://www.ijcai.org/Proceedings/15/Papers/582.pdf">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2015,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Peng Liu, Quanjie Yu, Zhiyong Wu, Shiyin Kang, Helen Meng, Lianhong Cai,
            "A Deep Recurrent Approach for Acoustic-to-Articulatory Inversion,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 4450-4454. Brisbane, Australia, April 19-24, 2015.
            <span class="text-lighten">(EI: 20154501510018, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/7178812">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2015,cf,ss,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yishuang Ning, Zhiyong Wu, Jia Jia, Fanbo Meng, Helen Meng, Lianhong Cai,
            "HMM-based Emphatic Speech Synthesis for Corrective Feedback in Computer-Aided Pronunciation Training,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 4934-4938. Brisbane, Australia, April 19-24, 2015.
            <span class="text-lighten">(EI: 20154501509415, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/7178909">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2015,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yishuang Ning, Zhiyong Wu, Xiaoyan Lou, Helen Meng, Jia Jia, Lianhong Cai,
            "Using Tilt for Automatic Emphasis Detection with Bayesian Networks,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 578-582. Dresden, Germany, September 6-10, 2015.
            <span class="text-lighten">(EI: 20160902029674, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/interspeech_2015/i15_0578.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2015,cf,ac"class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xixin Wu, Zhiyong Wu, Yishuang Ning, Jia Jia, Lianhong Cai, Helen Meng,
            "Understanding Speaking Styles of Internet Speech Data with LSTM and Low-resource Training,"
            [in] <i>Proc. International Conference on Affective Computing and Intelligent Interaction (ACII)</i>,
            pp. 815-820. Xi'an, China, September 21-24, 2015.
            <span class="text-lighten">(EI: 20161502238729)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/7344667">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2015,cf,ss,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            å­Ÿå‡¡åš, å´å¿—å‹‡, è´¾çˆ, è”¡èŽ²çº¢,
            "æ±‰è¯­é‡éŸ³çš„å‡¸æ˜¾åº¦åˆ†æžä¸Žåˆæˆ,"
            <i>å£°å­¦å­¦æŠ¥</i>,
            2015. 40(1): 1-11. January, 2015.
            ã€Fanbo Meng, Zhiyong Wu, Jia Jia, Lianhong Cai,
            "The Prominence Analysis and Synthesis of Emphasis in Putonghua,"
            <i>ACTA Acustica</i>,
            vol. 40, no. 1, pp. 1-11. January, 2015.ã€‘
            <span class="text-lighten">(EI: 20151000618075)</span>
            <a class="d-inline-block btn-round" href="https://www.cnki.com.cn/Article/CJFDTotal-XIBA201501001.htm">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2015,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            é»„é›¨æ™¨, å¾æ˜Žæ˜Ÿ, å´å¿—å‹‡, è”¡èŽ²çº¢,
            "è¡¨å¾å¥å¼è¯­æ°”çš„å£°å­¦ä¿¡æ¯åˆ†å¸ƒ,"
            [in] <i>å…¨å›½äººæœºè¯­éŸ³é€šè®¯å­¦æœ¯ä¼šè®® (NCMMSC)</i>.
            å¤©æ´¥, 2015.10.25-27.
            ã€Yuchen Huang, Mingxing Xu, Zhiyong Wu, Lianhong Cai,
            "Study on the Distribution of Acoustic Features Characterizing Sentence Intonation,"
            [in] <i>Proc. National Conference on Man-Machine Speech Communication (NCMMSC)</i>.
            Tianjin, China, October 25-27, 2015.ã€‘
            <span class="text-lighten"></span>
            <a class="d-inline-block btn-round" href="https://cpfd.cnki.com.cn/Article/CPFDTOTAL-SEER201510001124.htm">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2014,sel,jnl,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Fanbo Meng, Zhiyong Wu, Jia Jia, Helen Mebg, Lianhong Cai,
            "Synthesizing English Emphatic Speech for Multimodal Corrective Feedback in Computer-Aided Pronunciation Training,"
            <i>Multimedia Tools and Applications (MTA)</i>,
            vol. 73, no. 1, pp. 463-489. Springer, September, 2014.
            <span class="text-lighten">(SCI: WOS:000342418700022, EI: 20143600046713, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://link.springer.com/article/10.1007/s11042-013-1601-y">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2014,sel,jnl,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Jia Jia, Zhiyong Wu, Shen Zhang, Helen Meng, Lianhong Cai,
            "Head and Facial Gestures Synthesis using PAD Model for an Expressive Talking Avatar,"
            <i>Multimedia Tools and Applications (MTA)</i>,
            vol. 73, no. 1, pp. 439-461. Springer, September, 2014.
            <span class="text-lighten">(SCI: WOS:000342418700023, EI: 20143600046670, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://link.springer.com/article/10.1007/s11042-013-1604-8">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2014,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xin Zheng, Zhiyong Wu, Helen Meng, Lianhong Cai,
            "Contrastive Auto-encoder for Phoneme Recognition,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 2548-2552. Florence, Italy, May 4-9, 2014.
            <span class="text-lighten">(EI: 20143218037687, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6854056">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2014,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xin Zheng, Zhiyong Wu, Helen Meng, Lianhong Cai,
            "Learning Dynamic Features with Neural Networks for Phoneme Recognition,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 2543-2547. Florence, Italy, May 4-9, 2014.
            <span class="text-lighten">(EI: 20143218037686, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6854055">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2014,cf,ac,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xiao Zang, Zhiyong Wu, Helen Meng, Jia Jia, Lianhong Cai,
            "Using Conditional Random Fields to Predict Focus Word Pair in Spontaneous Spoken English,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 756-760. Singapore, September 14-18, 2014.
            <span class="text-lighten">(EI: 20144600199537, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/interspeech_2014/i14_0756.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2014,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xixin Wu, Zhiyong Wu, Jia Jia, Helen Meng, Lianhong Cai,
            "Automatic Speech Data Clustering with Human Perception based Weighted Distance,"
            [in] <i>Proc. International Symposium on Chinese Spoken Language Processing (ISCSLP)</i>,
            pp. 216-220. Singapore, September 14-18, 2014.
            <span class="text-lighten">(EI: 20144900274075)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6936604">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2014,cf,ac,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xiao Zang, Zhiyong Wu, Yishuang Ning, Helen Meng, Lianhong Cai,
            "Automatic Detection of Contrastive Word Pairs using Textual and Acoustic Features,"
            [in] <i>Proc. International Conference on Signal Processing Proceedings (ICSP)</i>,
            pp. 594-598. Hangzhou, China, October 19-23, 2014.
            <span class="text-lighten">(EI: 20153101078079)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/7015073">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2014,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yuchao Fan, Mingxing Xu, Zhiyong Wu, Lianhong Cai,
            "Automatic Emotion Variation Detection using Multi-Scaled Sliding Window,"
            [in] <i>Proc. IEEE International Conference on Orange Technologies (ICOT)</i>,
            pp. 229-233. Xi'an, China, September 20-23, 2014.
            <span class="text-lighten">(EI: 20145000323155)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6956642">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2014,jnl,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            çŽ‹æ¬£, å´å¿—å‹‡, è”¡èŽ²çº¢,
            "è¯­éŸ³åˆæˆä¸­åŸºäºŽç¨³å®šæ®µè¾¹ç•Œçš„ä¸å®šé•¿åŸºå…ƒé€‰å–,"
            <i>è½¯ä»¶å­¦æŠ¥</i>,
            2014, 25(S2): 63-69.
            ã€Xin Wang, Zhiyong Wu, Lianhong Cai,
            "Stable Boundary-based Non-uniform Unit Selection in Speech Synthesis,"
            <i>Journal of Software</i>,
            vol. 25, Supplement (2), pp. 63-69, December, 2014. Also
            [in] <i>ç¬¬ä¹å±Šå’Œè°äººæœºçŽ¯å¢ƒè”åˆå­¦æœ¯ä¼šè®® (HHME)</i>.
            å—æ˜Œ, 2013.9.27-28.ã€‘
            <span class="text-lighten">(EI: 20152100877399)</span>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2013,jnl,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            å­Ÿå‡¡åš, å´å¿—å‹‡, è’™ç¾ŽçŽ², è´¾çˆ, è”¡èŽ²çº¢,
            "åŸºäºŽå†³ç­–æ ‘çš„è‹±è¯­ç„¦ç‚¹è¯­éŸ³è½¬æ¢,"
            <i>æ¸…åŽå¤§å­¦å­¦æŠ¥(è‡ªç„¶ç§‘å­¦ç‰ˆ)</i>,
            2013, 53(7): 1046-1051.
            ã€Fanbo Meng, Zhiyong Wu, Helen Meng, Jia Jia, Lianhong Cai,
            "English Emphatic Speech Conversion based on a Decision Tree,"
            <i>Journal of Tsinghua University</i>,
            vol. 53, no. 7, pp. 1046-1051. July, 2013.ã€‘
            <span class="text-lighten">(EI: 20135217144112)</span>
            <a class="d-inline-block btn-round" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/201307_Tsinghua_FanboMENG_Emphatic.pdf">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2013,cf,sr" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xin Zheng, Zhiyong Wu, Binbin Shen, Helen Meng, Lianhong Cai,
            "Investigation of Tandem Deep Belief Network Approach for Phoneme Recognition,"
            [in] <i>Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 7586-7590. Vancouver, Canada, May 26-31, 2013.
            <span class="text-lighten">(EI: 20135217121577, CCF-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6639138">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2013,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Jianbo Jiang, Zhiyong Wu, Mingxing Xu, Jia Jia, Lianhong Cai,
            "Comparing Feature Dimension Reduction Algorithms for GMM-SVM based Speech Emotion Recognition,"
            [in] <i>Proc. Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</i>.
            Kaohsiung, China, October 29 - November 1, 2013.
            <span class="text-lighten">(EI: 20140717305313)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6694336">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2013,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Kai Zhao, Zhiyong Wu, Lianhong Cai,
            "A Real-time Speech Driven Talking Avatar based on Deep Neural Network,"
            [in] <i>Proc. Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</i>.
            Kaohsiung, China, October 29 - November 1, 2013.
            <span class="text-lighten">(EI: 20140717305312)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6694335">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2012,cf,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Jia Jia, Xiaohui Wang, Zhiyong Wu, Lianhong Cai, Helen Meng,
            "Modeling the Correlation between Modality Semantics and Facial Expressions,"
            [in] <i>Proc. Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</i>.
            Hollywood, USA, December 3-6, 2012.
            <span class="text-lighten">(EI: 20131016079234)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6411903">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2012,cf,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Jianbo Jiang, Zhiyong Wu, Mingxing Xu, Jia Jia, Lianhong Cai,
            "Comparison of Adaptation Methods for GMM-SVM based Speech Emotion Recognition,"
            [in] <i>Proc. IEEE Workshop on Spoken Language Technology (SLT)</i>,
            pp. 269-273. Miami, USA, December 2-5, 2012.
            <span class="text-lighten">(EI: 20130916065166)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6424234">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2012,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Tao Jiang, Zhiyong Wu, Jia Jia, Lianhong Cai,
            "Perceptual Clustering based Unit Selection Optimization for Concatenative Text-to-Speech Synthesis,"
            [in] <i>Proc. International Symposium on Chinese Spoken Language Processing (ISCSLP)</i>,
            pp. 64-68. Hong Kong, China, December 5-8, 2012.
            <span class="text-lighten">(EI: 20131016084519)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6423489">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2012,cf,ss,ac" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Chunrong Li, Zhiyong Wu, Fanbo Meng, Helen Meng, Lianhong Cai,
            "Detection and Emphatic Realization of Contrastive Word Pairs for Expressive Text-to-Speech Synthesis,"
            [in] <i>Proc. International Symposium on Chinese Spoken Language Processing (ISCSLP)</i>,
            pp. 93-97. Hong Kong, China, December 5-8, 2012.
            <span class="text-lighten">(EI: 20131016084523)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6423493">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2012,cf,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xixin Wu, Zhiyong Wu, Jia Jia, Lianhong Cai,
            "Adaptive Named Entity Recognition based on Conditional Random Fields with Automatic Updated Dynamic Gazetteers,"
            [in] <i>Proc. International Symposium on Chinese Spoken Language Processing (ISCSLP)</i>,
            pp. 363-367. Hong Kong, China, December 5-8, 2012.
            <span class="text-lighten">(EI: 20131016084525)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6423495">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2012,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Fanbo Meng, Zhiyong Wu, Helen Meng, Jia Jia, Lianhong Cai,
            "Hierarchical English Emphatic Speech Synthesis based on HMM with Limited Training Data,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 466-469. Portland, USA, September 8-13, 2012.
            <span class="text-lighten">(EI: 20132316399086, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/interspeech_2012/i12_0466.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2012,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Fanbo Meng, Zhiyong Wu, Helen Meng, Jia Jia, Lianhong Cai,
            "Generating Emphasis from Neutral Speech using Hierarchical Perturbation Model by Decision Tree and Support Vector Machine,"
            [in] <i>Proc. International Conference on Audio, Language and Image Processing (ICALIP)</i>,
            pp. 442-448. Shanghai, China, July 16-18, 2012.
            <span class="text-lighten">(EI: 20130315907216)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6376658">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2012,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Zhang Zhang, Zhiyong Wu, Jia Jia, Lianhong Cai,
            "Modeling Prosody Pattern of Chinese Expressive Speech and Its Application in Personalized Speech Conversion,"
            [in] <i>Proc. Proc. International Symposium on Tonal Aspects of Languages (TAL)</i>.
            Nanjing, China, May 26-29, 2012.
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/tal_2012/papers/tl12_O3-02.pdf">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2012,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Kai Zhao, Zhiyong Wu, Jia Jia, Lianhong Cai,
            "An Online Speech Driven Talking Head System,"
            [in] <i>Proc. IEEE Global High Tech Congress on Electronics (GHTCE)</i>,
            pp. 186-187. Shenzhen, China, November 18-20, 2012.
            <span class="text-lighten">(EI: 20131716244276)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6490153">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2012,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xin Wang, Zhiyong Wu,
            "An HMM-based Cantonese Speech Synthesis System,"
            [in] <i>Proc. IEEE Global High Tech Congress on Electronics (GHTCE)</i>,
            pp. 141-142. Shenzhen, China, November 18-20, 2012.
            <span class="text-lighten">(EI: 20131716244264)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6490141">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2012,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            å§œæ¶›, å´å¿—å‹‡, è”¡èŽ²çº¢,
            "è¯­éŸ³åˆæˆè‡ªç„¶åº¦çš„å®¢è§‚åº¦é‡å®žéªŒç ”ç©¶,"
            [in] <i>ç¬¬åå±Šä¸­å›½è¯­éŸ³å­¦å­¦æœ¯ä¼šè®® (PCC)</i>.
            ä¸Šæµ·, 2012.5.18-20.
            <span class="text-lighten"></span>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2011,jnl,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Hui Pang, Zhiyong Wu, Lianhong Cai,
            "Modeling Pitch Contour of Chinese Mandarin Sentences with the PENTA Model,"
            [in] <i>Proc. National Conference on Man-Machine Speech Communication (NCMMSC)</i>.
            Xi'an, China, October 16-18, 2011.
            Also published in
            <i>Tsinghua Science and Technology (æ¸…åŽå¤§å­¦å­¦æŠ¥è‹±æ–‡ç‰ˆ)</i>,
            vol. 17, no. 2, pp. 218-224. February, 2012.
            <span class="text-lighten">(EI: 20123215322698, <font color="#FF0000">Best Student Paper</font>)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6180048">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2011,cf,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Binbin Shen, Zhiyong Wu, Yongxin Wang, Lianhong Cai,
            "Combining Active and Semi-supervised Learning for Homograph Disambiguation in Mandarin Text-to-Speech Synthesis,"
            [in] <i>Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</i>,
            pp. 2165-2168. Florence, Italy, August 27-31, 2011.
            <span class="text-lighten">(EI: 20123715411045, CCF-C)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/interspeech_2011/i11_2165.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2011,cf,sv" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            é™ˆé¾™, å´å¿—å‹‡, è¢æ˜¥, è’™ç¾ŽçŽ², è”¡èŽ²çº¢,
            "é¢å‘æ•°å­—ç‰ˆæƒç®¡ç†çš„å£°çº¹è¾…åŠ©è®¤è¯ç³»ç»Ÿ,"
            [in] <i>ç¬¬åä¸€å±Šå…¨å›½äººæœºè¯­éŸ³é€šè®¯å­¦æœ¯ä¼šè®® (NCMMSC)</i>.
            é™•è¥¿, è¥¿å®‰, 2011.10.16-18.
            <span class="text-lighten"></span>
            <a class="d-inline-block btn-round" href="https://hcsi.cs.tsinghua.edu.cn/Paper/Paper11/ChenLong_NCMMSC.pdf">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2010,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Zhiyong Wu, Lianhong Cai, Helen Meng,
            "Modeling Prosody Patterns for Chinese Expressive Text-to-Speech Synthesis,"
            [in] <i>Proc. International Symposium on Chinese Spoken Language Processing (ISCSLP)</i>,
            pp. 148-152. Tainan, China, November 29 - December 3, 2010.
            <span class="text-lighten">(EI: 20110713663203)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/5684494">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2010,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Fanbo Meng, Helen Meng, Zhiyong Wu, Lianhong Cai,
            "Synthesizing Expressive Speech to Convey Focus using a Perturbation Model for Computer-Aided Pronunciation Training,"
            [in] <i>Proc. Second Language Studies: Acquisition, Learning, Education and Technology (L2WS)</i>,
            pp. 1-4. Tokyo, Japan, September 22-27, 2010.
            <span class="text-lighten"></span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/L2WS_2010/papers/lw10_P2-9.pdf">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2010,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Quansheng Duan, Shiyin Kang, Zhiyong Wu, Lianhong Cai, Zhiwei Shuang, Yong Qin,
            "Comparison of Syllable/Phone HMM Based Mandarin TTS,"
            [in] <i>Proc. International Conference on Pattern Recognition (ICPR)</i>,
            pp. 4496-4499. Istanbul, Turkey, August 23-26, 2010.
            <span class="text-lighten">(EI: 20104613390878, THU-B)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/5597845">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2010,cf,ss,ac,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Shen Zhang, Zhiyong Wu, Helen Meng, Lianhong Cai,
            "Facial Expression Synthesis based on Emotion Dimensions for Affective Talking Avatar,"
            <i>Smart Innovation, Systems and Technologies (SIST), Modeling Machine Emotions for Realizing Intelligence</i>,
            vol. 2010, no. 1, pp. 109-132. Springer, 2010.
            <span class="text-lighten">(EI: 20123715421851)</span>
            <a class="d-inline-block btn-round" href="https://link.springer.com/chapter/10.1007/978-3-642-12604-8_6">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2010,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            å¼ ç« , è´¾çˆ, è”¡èŽ²çº¢, å´å¿—å‹‡,
            "æ±‰è¯­éŸ³é«˜æ¨¡å¼åŠå‚æ•°åŒ–æè¿°çš„ç ”ç©¶,"
            [in] <i>ç¬¬ä¹å±Šä¸­å›½è¯­éŸ³å­¦å­¦æœ¯ä¼šè®® (PCC)</i>.
            å¤©æ´¥, 2010.5.28-30.
            <span class="text-lighten"></span>
            <a class="d-inline-block btn-round" href="https://hcsi.cs.tsinghua.edu.cn/Paper/Paper10/zhang_PCC2010.pdf">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2009,sel,jnl,ac,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Zhiyong Wu, Helen Meng, Hongwu Yang, Lianhong Cai,
            "Modeling the Expressivity of Input Text Semantics for Chinese Text-to-Speech Synthesis in a Spoken Dialog System,"
            <i>IEEE Transaction on Audio, Speech and Language Processing (TASLP)</i>,
            vol. 17, no. 8, pp. 1567-1577. IEEE, November, 2009.
            <span class="text-lighten">(SCI: WOS:000268903600010, EI: 20093612281690, THU-A)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/4926212">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2009,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Zhiyong Wu, Guangqi Cao, Helen Meng, Lianhong Cai,
            "A Unified Framework for Multilingual Text-to-Speech Synthesis with SSML Specification as Interface,"
            [in] <i>Proc. National Conference on Man-Machine Speech Communication (NCMMSC)</i>.
            Lanzhou, Gansu, August 14-16, 2009.
            Also published in
            <i>Tsinghua Science and Technology (æ¸…åŽå¤§å­¦å­¦æŠ¥è‹±æ–‡ç‰ˆ)</i>,
            vol. 14, no. 5, pp. 623-630, October 2009.
            <span class="text-lighten">(EI: 20094012358727)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/6076262">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2009,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            æ®µå…¨ç››, åº·ä¸–èƒ¤, åŒå¿—ä¼Ÿ, å´å¿—å‹‡, è”¡èŽ²çº¢, ç§¦å‹‡,
            "ä¸€ç§é€‚åˆHMMæ±‰è¯­è¯­éŸ³åˆæˆçš„å»ºæ¨¡å•å…ƒæŒ‘é€‰ç®—æ³•,"
            [in] <i>ç¬¬åå±Šå…¨å›½äººæœºè¯­éŸ³é€šè®¯å­¦æœ¯ä¼šè®® (NCMMSC)</i>,
            pp. 434-439. ç”˜è‚ƒ, å…°å·ž, August 14-16, 2009.
            <span class="text-lighten"></span>
            <a class="d-inline-block btn-round" href="https://hcsi.cs.tsinghua.edu.cn/Paper/paper09/7_duan_NCMMSC2009.pdf">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2008,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Honglei Cong, Zhiyong Wu, Lianhong Cai, Helen Meng,
            "A New Prosodic Strength Calculation Method for Prosody Reduction Modeling,"
            [in] <i>Proc. International Symposium on Chinese Spoken Language Processing (ISCSLP)</i>,
            pp. 53-56. Kunming, China, December 16-19, 2008.
            <span class="text-lighten">(EI: 20091011939031, <font color="#FF0000">Best Paper Finalist</font>)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/4730279">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2008,cf,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Zhiyong Wu, Jiying Wu, Helen Meng,
            "The Use of Dynamic Deformable Templates for Lip Tracking in an Audio-Visual Corpus with Large Variations in Head Pose, Face Illumination and Lip Shapes,"
            [in] <i>Proc. International Symposium on Chinese Spoken Language Processing (ISCSLP)</i>,
            pp. 370-373. Kunming, China, December 16-19, 2008.
            <span class="text-lighten">(EI: 20091011939107)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/4730358">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2008,cf,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Xinxin Zhou, Zhiyong Wu, Chun Yuan, Yuzhuo Zhong,
            "Document Structure Analysis and Text Normalization for Chinese Putonghua and Cantonese Text-to-Speech Synthesis,"
            [in] <i>Proc. International Symposium on Intelligent Information Technology Application (IITA)</i>,
            pp. 477-481. Shanghai, China, December 20-22, 2008.
            <span class="text-lighten">(EI: 20091411996990)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/4739619">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2008,cf,sv" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Yu Wang, Zhiyong Wu, Lianhong Cai, Helen Meng,
            "Modeling the Synchrony between Audio and Visual Modalities for Speaker Identification,"
            [in] <i>Proc. Phonetic Conference of China and the International Symposium on Phonetic Frontiers (PCC)</i>,
            pp. 1-5. Beijing, China, April 18-20, 2008.
            <span class="text-lighten"></span>
            <a class="d-inline-block btn-round" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/PCC2008_WANG_YU.pdf">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2007,cf,ac,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Shen Zhang, Zhiyong Wu, Helen Meng, Lianhong Cai,
            "Facial Expression Synthesis Using PAD Emotional Parameters for a Chinese Expressive Avatar,"
            [in] <i>Proc. International Conference on Affective Computing and Intelligent Interaction (ACII)</i>,
            pp. 24-35. Lisbon, Portugal, September 12-14, 2007.
            <span class="text-lighten">(EI: 20080311024879)</span>
            <a class="d-inline-block btn-round" href="https://link.springer.com/chapter/10.1007/978-3-540-74889-2_3">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2007,cf,ac,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Shen Zhang, Zhiyong Wu, Helen Meng, Lianhong Cai,
            "Head Movement Synthesis based on Semantic and Prosodic Features for a Chinese Expressive Avatar,"
            [in] <i>Proc. International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>,
            pp. 837-840. Hawaii, USA, April 15-20, 2007.
            <span class="text-lighten">(EI: 20073210745929)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/4218231">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2006,cf,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Zhiyong Wu, Helen Meng, Hui Ning, Sam Tse,
            "A Corpus-based Approach for Cooperative Response Generation in a Dialog System,"
            <i>Lecture Notes in Computer Science</i>,
            [in] <i>Proc. International Symposium on Chinese Spoken Language Processing (ISCSLP)</i>,
            pp. 614-626. Singapore, December 13-16, 2006.
            <span class="text-lighten">(SCI: WOS:000244824800058, EI: 20100912736122)</span>
            <a class="d-inline-block btn-round" href="https://link.springer.com/chapter/10.1007/11939993_63">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2006,cf,ac,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Hongwu Yang, Helen Meng, Zhiyong Wu, Lianhong Cai,
            "Modelling the Global Acoustic Correlates of Expressivity for Chinese Text-to-speech Synthesis,"
            [in] <i>IEEE/ACL Workshop on Spoken Language Technology (SLT)</i>,
            pp. 138-141. Palm Beach, Aruba, December 10-13, 2006.
            <span class="text-lighten">(EI: 20083311451167)</span>
            <a class="d-inline-block btn-round" href="https://ieeexplore.ieee.org/abstract/document/4123381">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2006,cf,ac,ss,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Zhiyong Wu, Shen Zhang, Lianhong Cai, Helen Meng,
            "Real-time Synthesis of Chinese Visual Speech and Facial Expressions using MPEG-4 FAP Features in a Three-dimensional Avatar,"
            [in] <i>Proc. International Conference on Spoken Language Processing (INTERSPEECH - ICSLP)</i>,
            pp. 1802-1805. Pittsburgh, USA, September 17-21, 2006.
            <span class="text-lighten">(EI: 20082511324456)</span>
            <a class="d-inline-block btn-round" href="https://www.isca-speech.org/archive_v0/interspeech_2006/i06_1823.html">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2006,cf,sv" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Zhiyong Wu, Lianhong Cai, Helen Meng,
            "Weight Estimation for Audio-Visual Multi-level Fusion in Bimodal Speaker Identification,"
            <i>Lecture Notes in Control and Information Science</i>,
            [in] <i>Proc. International Conference on Intelligent Computing (ICIC)</i>,
            pp. 1107-1112. Kunming, China, August 16-19, 2006.
            <span class="text-lighten">(SCI: WOS:000240385300144)</span>
            <a class="d-inline-block btn-round" href="https://link.springer.com/chapter/10.1007/978-3-540-37258-5_144">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2006,jnl,sv" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            å´å¿—å‹‡, è”¡èŽ²çº¢,
            "åŸºäºŽåŠ¨æ€è´å¶æ–¯ç½‘ç»œçš„éŸ³è§†é¢‘åŒæ¨¡æ€è¯´è¯äººè¯†åˆ«,"
            <i>è®¡ç®—æœºç ”ç©¶ä¸Žå‘å±•</i>,
            2006: 43(3), 470-475.
            ã€Zhiyong Wu, Lianhong Cai,
            "Audio-Visual Bimodal Speaker Identification Using Dynamic Bayesian Networks,"
            <i>Journal of Computer Research and Development</i>,
            vol.43, no.3, pp.470-475. March, 2006.ã€‘
            <span class="text-lighten">(EI: 2006239925198)</span>
            <a class="d-inline-block btn-round" href="https://www.cnki.com.cn/Article/CJFD2006-JFYZ200603015.htm">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2006,jnl,sv" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            å´å¿—å‹‡, è”¡èŽ²çº¢, é©¬ç£Š, è´¾çˆ,
            "å¤šç”Ÿç‰©ç‰¹å¾è¯†åˆ«å¹³å°çš„è®¾è®¡ä¸Žå®žçŽ°,"
            <i>å°åž‹å¾®åž‹è®¡ç®—æœºç³»ç»Ÿ</i>,
            2006: 27(2), 375-379.
            ã€Zhiyong Wu, Lianhong Cai, Lei Ma, Jia Jia,
            "Design and Implementation of a Multi-Biometric Platform,"
            <i>Mini-Micro Systems</i>,
            vol.27, no.2, pp.375-379. February, 2006.ã€‘
            <span class="text-lighten"></span>
            <a class="d-inline-block btn-round" href="https://www.cnki.com.cn/Article/CJFDTotal-XXWX200602043.htm">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2006,cf,sv" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            Zhiyong Wu, Lianhong Cai, Helen Meng,
            "Multi-level Fusion of Audio and Visual Features for Speaker Identification,"
            <i>Lecture Notes in Computer Science</i>,
            [in] <i>Proc. International Conference on Biometrics (ICB)</i>,
            pp. 493-499. Hong Kong, China, January 5-7, 2006.
            <span class="text-lighten">(SCI: WOS:000235768300066, EI: 2006249940530)</span>
            <a class="d-inline-block btn-round" href="https://link.springer.com/chapter/10.1007/11608288_66">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2005,cf,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            å´å¿—å‹‡, è”¡èŽ²çº¢, è’™ç¾ŽçŽ²,
            "å¯è§†è¯­éŸ³åˆæˆä¸­åŸºäºŽéŸ³è§†é¢‘å…³è”æ¨¡åž‹çš„è§†ä½å‚æ•°ä¼˜åŒ–,"
            [in] <i>ç¬¬å…­å±Šå…¨å›½äººæœºè¯­éŸ³é€šè®¯å­¦æœ¯ä¼šè®® (NCMMSC)</i>,
            pp. 334-337. åŒ—äº¬,  October 22-24, 2005.
            <span class="text-lighten">(<font color="#FF0000">Best Paper</font>)</span>
            <a class="d-inline-block btn-round" href="https://www.cnki.com.cn/Article/CPFDTOTAL-ZGZR200510001079.htm">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2005,jnl,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            å´å¿—å‹‡, è”¡èŽ²çº¢, è”¡é”,
            "è¯­éŸ³åˆæˆä¸­åŸºäºŽå¬è¾¨æŒ‡å¯¼çš„æƒé‡è®­ç»ƒç®—æ³•,"
            <i>æ¸…åŽå¤§å­¦å­¦æŠ¥(è‡ªç„¶ç§‘å­¦ç‰ˆ)</i>,
            2005: 45(1), 52-56.
            ã€Zhiyong Wu, Lianhong Cai, Rui Cai,
            "Perceptual Evaluation Weight Training for Text-to-Speech Synthesis,"
            <i>Journal of Tsinghua University</i>,
            vol. 45, no. 1, pp. 52-56. January, 2005.ã€‘
            <span class="text-lighten">(EI: 2005139014229)</span>
            <a class="d-inline-block btn-round" href="https://www.cnki.com.cn/Article/CJFDTotal-QHXB200501014.htm">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2005,jnl,ss" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            å´å¿—å‹‡, è”¡èŽ²çº¢,
            "è¯­éŸ³åˆæˆä¸­çš„éŸµå¾‹å…³è”æ¨¡åž‹,"
            <i>ä¸­æ–‡ä¿¡æ¯å­¦æŠ¥</i>,
            2004: 18(2), 44-50.
            ã€Zhiyong Wu, Lianhong Cai,
            "Prosodic Correlation Model in Text-to-Speech Synthesis,"
            <i>Journal of Chinese Information Processing</i>,
            vol. 18, no. 2, pp. 44-50. February, 2004.ã€‘
            <span class="text-lighten"></span>
            <a class="d-inline-block btn-round" href="https://www.cnki.com.cn/Article/CJFD2004-MESS200402006.htm">Paper</a>
          </div>
        </div>
      </div>
      <!-- paper -->
      <div data-category="2005,jnl,mslp" class="col-12 filtr-item">
        <div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2">
          <div class="text-dark">
            çŽ‹å¿—æ˜Ž, è”¡èŽ²çº¢, å´å¿—å‹‡, é™¶å»ºåŽ,
            "æ±‰è¯­æ–‡æœ¬-å¯è§†è¯­éŸ³è½¬æ¢çš„ç ”ç©¶,"
            <i>å°åž‹å¾®åž‹è®¡ç®—æœºç³»ç»Ÿ</i>,
            2002: 23(4), 474-477.
            ã€Zhiming Wang, Lianhong Cai, Zhiyong Wu, Jianhua Tao,
            "Study of Text to Visual Speech in Chinese,"
            <i>Minimicro Systems</i>,
            vol. 23, no. 4, pp. 474-477. April, 2002.ã€‘
            <span class="text-lighten"></span>
            <a class="d-inline-block btn-round" href="https://www.cnki.com.cn/Article/CJFDTotal-XXWX200204026.htm">Paper</a>
          </div>
        </div>
      </div>
      <!-- done -->
    </div>
  </div>
</section>
<!-- /papers -->

<!-- footer -->
<footer>
  <!-- footer content -->
  <div class="footer bg-footer section border-bottom">
    <div class="container">
      <div class="row">
        <div class="col-lg-4 col-md-4 col-sm-5 mb-5 mb-sm-0 text-center">
          <!-- logo -->
          <a class="logo-footer" href="index.html"><img class="img-fluid mb-0" src="images/QRCode.png" alt="QR code"></a>
        </div>
        <!-- contact -->
        <div class="col-lg-8 col-md-8 col-sm-7 mb-0">
          <h4 class="text-lightblue mb-2">Location</h4>
          <p class="text-white mb-4">Room 1701, Information Building, Tsinghua Campus, The University Town, Shenzhen 518055, China <br>
            æ·±åœ³å¸‚å—å±±åŒºè¥¿ä¸½å¤§å­¦åŸŽæ¸…åŽæ ¡åŒºä¿¡æ¯å¤§æ¥¼1701
          </p>
          <h4 class="text-lightblue mb-2">Follow Us</h4>
          <p class="text-white mb-0">Scan QR code to follow us on WeChat <br>
            æ‰«ç å…³æ³¨å®žéªŒå®¤å¾®ä¿¡å…¬ä¼—å·
          </p>
        </div>
      </div>
    </div>
  </div>
  <!-- copyright -->
  <div class="copyright py-4 bg-footer">
    <div class="container">
      <div class="row">
        <div class="col-sm-7 text-sm-left text-center">
          <p class="mb-0">Copyright &copy;
            <script>
              var CurrentYear = new Date().getFullYear()
              document.write(CurrentYear)
            </script>,
            im1eon @ thuhcsi</p>
        </div>
      </div>
    </div>
  </div>
</footer>
<!-- /footer -->

<!-- jQuery -->
<script src="plugins/jQuery/jquery.min.js"></script>
<!-- Bootstrap JS -->
<script src="plugins/bootstrap/bootstrap.min.js"></script>
<!-- slick slider -->
<script src="plugins/slick/slick.min.js"></script>
<!-- aos -->
<script src="plugins/aos/aos.js"></script>
<!-- venobox popup -->
<script src="plugins/venobox/venobox.min.js"></script>
<!-- filter -->
<script src="plugins/filterizr/jquery.filterizr.min.js"></script>

<!-- Main Script -->
<script src="js/script.js"></script>

</body>
</html>
